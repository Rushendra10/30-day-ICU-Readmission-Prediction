{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a21dc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901ba47",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38056999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = \"data/physionet.org/files/mimiciii/1.4/\"\n",
    "OUTPUT_FILE = \"clean_dataset.csv\"\n",
    "\n",
    "# Vital item IDs (MIMIC-III standard)\n",
    "VITALS = {\n",
    "    \"HR\": [220045],\n",
    "    \"SysBP\": [220179, 51],\n",
    "    \"DiasBP\": [220180, 8368],\n",
    "    \"MeanBP\": [220181],\n",
    "    \"RR\": [220210],\n",
    "    \"SpO2\": [220277],\n",
    "    \"TempC\": [223761, 678],\n",
    "}\n",
    "\n",
    "# Lab item IDs\n",
    "LABS = {\n",
    "    \"WBC\": [51300],\n",
    "    \"HGB\": [51222],\n",
    "    \"Platelets\": [51265],\n",
    "    \"Sodium\": [50983],\n",
    "    \"Potassium\": [50971],\n",
    "    \"Creatinine\": [50912],\n",
    "    \"BUN\": [51006],\n",
    "}\n",
    "\n",
    "\n",
    "vital_ids = set([i for ids in VITALS.values() for i in ids])\n",
    "lab_ids = set([i for ids in LABS.values() for i in ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a540a",
   "metadata": {},
   "source": [
    "### Loading Core Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f243f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_core_tables():\n",
    "    print(\"Loading core tables\")\n",
    "\n",
    "    patients = pd.read_csv(DATA_DIR + \"PATIENTS.csv.gz\", compression=\"gzip\", parse_dates=[\"DOB\"])\n",
    "\n",
    "    admissions = pd.read_csv(DATA_DIR + \"ADMISSIONS.csv.gz\", compression=\"gzip\", parse_dates=[\"ADMITTIME\", \"DISCHTIME\"])\n",
    "\n",
    "    icustays = pd.read_csv(DATA_DIR + \"ICUSTAYS.csv.gz\", compression=\"gzip\", parse_dates=[\"INTIME\", \"OUTTIME\"])\n",
    "\n",
    "    diagnoses = pd.read_csv(DATA_DIR + \"DIAGNOSES_ICD.csv.gz\", compression=\"gzip\")\n",
    "\n",
    "    return patients, admissions, icustays, diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c894b7",
   "metadata": {},
   "source": [
    "### Merging Core Tables on ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39665873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_core(patients, admissions, icustays):\n",
    "    print(\"Merging PATIENTS + ADMISSIONS + ICUSTAYS\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1. Clean DOB\n",
    "    # --------------------------------------------------------\n",
    "    patients[\"DOB\"] = pd.to_datetime(patients[\"DOB\"], errors=\"coerce\")\n",
    "    patients = patients[patients[\"DOB\"].notna()]\n",
    "    patients = patients[patients[\"DOB\"].dt.year.between(1870, 2200)]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. Merge PATIENTS + ADMISSIONS\n",
    "    # --------------------------------------------------------\n",
    "    adm_pat = admissions.merge(patients, on=\"SUBJECT_ID\", how=\"left\")\n",
    "\n",
    "    adm_pat[\"ADMITTIME\"] = pd.to_datetime(adm_pat[\"ADMITTIME\"], errors=\"coerce\")\n",
    "    adm_pat[\"DISCHTIME\"] = pd.to_datetime(adm_pat[\"DISCHTIME\"], errors=\"coerce\")\n",
    "\n",
    "    adm_pat = adm_pat.dropna(subset=[\"ADMITTIME\", \"DISCHTIME\"])\n",
    "    adm_pat = adm_pat[adm_pat[\"ADMITTIME\"].dt.year.between(2000, 3000)]\n",
    "    adm_pat = adm_pat[adm_pat[\"DISCHTIME\"].dt.year.between(2000, 3000)]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3. Merge ICU stays\n",
    "    # --------------------------------------------------------\n",
    "    merged = adm_pat.merge(\n",
    "        icustays,\n",
    "        on=[\"SUBJECT_ID\", \"HADM_ID\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    merged[\"INTIME\"] = pd.to_datetime(merged[\"INTIME\"], errors=\"coerce\")\n",
    "    merged[\"OUTTIME\"] = pd.to_datetime(merged[\"OUTTIME\"], errors=\"coerce\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4. AGE CALCULATION\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    y1 = merged[\"ADMITTIME\"].dt.year\n",
    "    m1 = merged[\"ADMITTIME\"].dt.month\n",
    "    d1 = merged[\"ADMITTIME\"].dt.day\n",
    "\n",
    "    y0 = merged[\"DOB\"].dt.year\n",
    "    m0 = merged[\"DOB\"].dt.month\n",
    "    d0 = merged[\"DOB\"].dt.day\n",
    "\n",
    "    age = y1 - y0\n",
    "\n",
    "    birthday_not_reached = (m1 < m0) | ((m1 == m0) & (d1 < d0))\n",
    "    age = age - birthday_not_reached.astype(int)\n",
    "\n",
    "    valid_age = (\n",
    "        merged[\"ADMITTIME\"].notna() &\n",
    "        merged[\"DOB\"].notna() &\n",
    "        y1.between(1900, 2300) &\n",
    "        y0.between(1900, 2300) &\n",
    "        (age >= 0) &\n",
    "        (age < 200)\n",
    "    )\n",
    "\n",
    "    age = age.astype(\"float\")\n",
    "    age[~valid_age] = np.nan\n",
    "    age[age > 120] = 90\n",
    "\n",
    "    merged[\"AGE\"] = age\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9b201",
   "metadata": {},
   "source": [
    "### Computing the 30-day Readmission Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18738b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_readmission(df):\n",
    "    print(\"Computing 30-day readmission labels\")\n",
    "\n",
    "    df = df.sort_values([\"SUBJECT_ID\", \"ADMITTIME\"])\n",
    "\n",
    "    df[\"NEXT_ADMITTIME\"] = df.groupby(\"SUBJECT_ID\")[\"ADMITTIME\"].shift(-1)\n",
    "    df[\"HOURS_TO_NEXT\"] = (\n",
    "        (df[\"NEXT_ADMITTIME\"] - df[\"DISCHTIME\"]).dt.total_seconds() / 3600\n",
    "    )\n",
    "\n",
    "    df[\"READMIT_30D\"] = (df[\"HOURS_TO_NEXT\"] <= 720).astype(int)\n",
    "    df[\"READMIT_30D\"] = df[\"READMIT_30D\"].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397210c",
   "metadata": {},
   "source": [
    "### Diagnosis-based Comorbidity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comorbidities(diagnoses):\n",
    "    print(\"Generating diagnosis-based comorbidity features (Elixhauser)\")\n",
    "\n",
    "    # Load Elixhauser mappings (ICD9 prefix → binary comorbidity)\n",
    "    # For simplicity, use common ICD9→Elixhauser mapping\n",
    "    elix_map = {\n",
    "        \"250\": \"Diabetes\",\n",
    "        \"428\": \"CHF\",\n",
    "        \"414\": \"CAD\",\n",
    "        \"401\": \"Hypertension\",\n",
    "        \"585\": \"Renal_Failure\",\n",
    "        \"491\": \"COPD\",\n",
    "        \"571\": \"Liver_Disease\",\n",
    "        \"518\": \"Respiratory_Failure\",\n",
    "        \"410\": \"AMI\",\n",
    "        \"038\": \"Sepsis\",\n",
    "    }\n",
    "\n",
    "    diagnoses[\"icd_prefix\"] = diagnoses[\"ICD9_CODE\"].astype(str).str[:3]\n",
    "    diagnoses[\"flag\"] = 1\n",
    "\n",
    "    pivot = {}\n",
    "    for prefix, name in elix_map.items():\n",
    "        filtered = diagnoses[diagnoses[\"icd_prefix\"] == prefix]\n",
    "        flags = filtered.pivot_table(\n",
    "            index=\"HADM_ID\",\n",
    "            values=\"flag\",\n",
    "            aggfunc=\"max\"\n",
    "        ).rename(columns={\"flag\": name})\n",
    "        pivot[name] = flags\n",
    "\n",
    "    comorb = pd.concat(pivot.values(), axis=1)\n",
    "    comorb = comorb.fillna(0)\n",
    "\n",
    "    return comorb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600a306",
   "metadata": {},
   "source": [
    "### Vitals from the first 24 hours of ICU Admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vitals(merged):\n",
    "    print(\"Extracting 24-hour vitals (efficient)\")\n",
    "\n",
    "    hadm_info = merged[[\"HADM_ID\", \"ADMITTIME\"]].drop_duplicates()\n",
    "    hadm_info = hadm_info.dropna(subset=[\"HADM_ID\", \"ADMITTIME\"])\n",
    "    hadm_info[\"HADM_ID\"] = hadm_info[\"HADM_ID\"].astype(\"int64\")\n",
    "\n",
    "    chunksize = 3_000_000\n",
    "    rows = []\n",
    "\n",
    "    for chunk in pd.read_csv(\n",
    "        DATA_DIR + \"CHARTEVENTS.csv.gz\",\n",
    "        compression=\"gzip\",\n",
    "        chunksize=chunksize,\n",
    "        usecols=[\"HADM_ID\", \"ITEMID\", \"CHARTTIME\", \"VALUENUM\"]\n",
    "    ):\n",
    "        chunk = chunk.dropna(subset=[\"HADM_ID\"])\n",
    "        chunk[\"HADM_ID\"] = chunk[\"HADM_ID\"].astype(\"int64\")\n",
    "        chunk = chunk[chunk[\"ITEMID\"].isin(vital_ids)]\n",
    "        chunk[\"CHARTTIME\"] = pd.to_datetime(chunk[\"CHARTTIME\"])\n",
    "\n",
    "        # Merge admission times onto chunk\n",
    "        merged_chunk = chunk.merge(hadm_info, on=\"HADM_ID\", how=\"inner\")\n",
    "\n",
    "        # Keep rows within first 24 hours\n",
    "        window_start = merged_chunk[\"ADMITTIME\"]\n",
    "        window_end = merged_chunk[\"ADMITTIME\"] + pd.Timedelta(hours=24)\n",
    "\n",
    "        mask = (merged_chunk[\"CHARTTIME\"] >= window_start) & (\n",
    "            merged_chunk[\"CHARTTIME\"] <= window_end\n",
    "        )\n",
    "\n",
    "        merged_chunk = merged_chunk[mask]\n",
    "\n",
    "        if merged_chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # Aggregate: mean/min/max per HADM_ID per vital\n",
    "        grp = merged_chunk.groupby([\"HADM_ID\", \"ITEMID\"])[\"VALUENUM\"].agg([\"mean\", \"min\", \"max\"]).reset_index()\n",
    "        rows.append(grp)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"HADM_ID\"])\n",
    "\n",
    "    vitals_raw = pd.concat(rows)\n",
    "\n",
    "    # Pivot to wide format\n",
    "    vitals_wide = vitals_raw.pivot_table(\n",
    "        index=\"HADM_ID\",\n",
    "        columns=\"ITEMID\",\n",
    "        values=[\"mean\", \"min\", \"max\"]\n",
    "    )\n",
    "\n",
    "    vitals_wide.columns = [f\"{stat}_{itemid}\" for stat, itemid in vitals_wide.columns]\n",
    "    vitals_wide = vitals_wide.reset_index()\n",
    "\n",
    "    return vitals_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c7dd80",
   "metadata": {},
   "source": [
    "### Lab Results from the first 24 hours of ICU Admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labs(merged):\n",
    "    print(\"Extracting 24-hour labs (efficient)\")\n",
    "\n",
    "    hadm_info = merged[[\"HADM_ID\", \"ADMITTIME\"]].drop_duplicates()\n",
    "    hadm_info = hadm_info.dropna(subset=[\"HADM_ID\", \"ADMITTIME\"])\n",
    "    hadm_info[\"HADM_ID\"] = hadm_info[\"HADM_ID\"].astype(\"int64\")\n",
    "\n",
    "    chunksize = 3_000_000\n",
    "    rows = []\n",
    "\n",
    "    for chunk in pd.read_csv(\n",
    "        DATA_DIR + \"LABEVENTS.csv.gz\",\n",
    "        compression=\"gzip\",\n",
    "        chunksize=chunksize,\n",
    "        usecols=[\"HADM_ID\", \"ITEMID\", \"CHARTTIME\", \"VALUENUM\"]\n",
    "    ):\n",
    "        # Drop missing HADM_ID\n",
    "        chunk = chunk.dropna(subset=[\"HADM_ID\"])\n",
    "        chunk[\"HADM_ID\"] = chunk[\"HADM_ID\"].astype(\"int64\")\n",
    "\n",
    "        # Filter only labs we care about\n",
    "        chunk = chunk[chunk[\"ITEMID\"].isin(lab_ids)]\n",
    "\n",
    "        # Parse timestamp\n",
    "        chunk[\"CHARTTIME\"] = pd.to_datetime(chunk[\"CHARTTIME\"], errors=\"coerce\")\n",
    "\n",
    "        # Merge admission start times onto this chunk\n",
    "        merged_chunk = chunk.merge(hadm_info, on=\"HADM_ID\", how=\"inner\")\n",
    "\n",
    "        # Filter for first 24 hours\n",
    "        starts = merged_chunk[\"ADMITTIME\"]\n",
    "        ends = starts + pd.Timedelta(hours=24)\n",
    "\n",
    "        mask = (merged_chunk[\"CHARTTIME\"] >= starts) & (merged_chunk[\"CHARTTIME\"] <= ends)\n",
    "        merged_chunk = merged_chunk[mask]\n",
    "\n",
    "        if merged_chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # Compute mean/min/max per lab item per admission\n",
    "        grp = (\n",
    "            merged_chunk\n",
    "            .groupby([\"HADM_ID\", \"ITEMID\"])[\"VALUENUM\"]\n",
    "            .agg([\"mean\", \"min\", \"max\"])\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        rows.append(grp)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"HADM_ID\"])\n",
    "\n",
    "    labs_raw = pd.concat(rows)\n",
    "\n",
    "    # Pivot the ITEMID columns into wide feature columns\n",
    "    labs_wide = labs_raw.pivot_table(\n",
    "        index=\"HADM_ID\",\n",
    "        columns=\"ITEMID\",\n",
    "        values=[\"mean\", \"min\", \"max\"]\n",
    "    )\n",
    "\n",
    "    labs_wide.columns = [f\"{stat}_{itemid}\" for stat, itemid in labs_wide.columns]\n",
    "    labs_wide = labs_wide.reset_index()\n",
    "\n",
    "    return labs_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10838c71",
   "metadata": {},
   "source": [
    "### Final Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all(merged, comorb, vital24, lab24):\n",
    "    print(\"Merging all features into final dataset\")\n",
    "\n",
    "    df = (\n",
    "        merged\n",
    "        # Diagnosis features: by admission\n",
    "        .merge(comorb, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "        # Vitals: now by admission\n",
    "        .merge(vital24, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "        # Labs: also by admission\n",
    "        .merge(lab24, on=\"HADM_ID\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    # Final cleaning\n",
    "    df = df.fillna(df.median(numeric_only=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d6049",
   "metadata": {},
   "source": [
    "### Full Dataset Preparation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a8575bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading core tables...\n",
      "Merging PATIENTS + ADMISSIONS + ICUSTAYS...\n",
      "Computing 30-day readmission labels...\n",
      "Generating diagnosis-based comorbidity features (Elixhauser)...\n",
      "Extracting 24-hour vitals (efficient)...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "patients, admissions, icustays, diagnoses = load_core_tables()\n",
    "merged = merge_core(patients, admissions, icustays)\n",
    "merged = compute_readmission(merged)\n",
    "\n",
    "comorb = create_comorbidities(diagnoses)\n",
    "vital24 = extract_vitals(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e81e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 24-hour labs (efficient)...\n",
      "Merging all features into final dataset...\n",
      "Saving final dataset...\n",
      "Done! Final shape: (62722, 101)\n"
     ]
    }
   ],
   "source": [
    "lab24 = extract_labs(merged)\n",
    "\n",
    "final = merge_all(merged, comorb, vital24, lab24)\n",
    "\n",
    "print(\"Saving final dataset\")\n",
    "final.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Done! Final shape: {final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU stays present in merged: 0\n",
      "Unique ICU stays: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"ICU stays present in merged:\", merged[\"ICUSTAY_ID\"].notna().sum())\n",
    "print(\"Unique ICU stays:\", merged[\"ICUSTAY_ID\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ea3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'DBSOURCE',\n",
      "       'FIRST_CAREUNIT', 'LAST_CAREUNIT', 'FIRST_WARDID', 'LAST_WARDID',\n",
      "       'INTIME', 'OUTTIME', 'LOS'],\n",
      "      dtype='object')\n",
      "   ROW_ID  SUBJECT_ID  HADM_ID  ICUSTAY_ID DBSOURCE FIRST_CAREUNIT  \\\n",
      "0     365         268   110404      280836  carevue           MICU   \n",
      "1     366         269   106296      206613  carevue           MICU   \n",
      "2     367         270   188028      220345  carevue            CCU   \n",
      "3     368         271   173727      249196  carevue           MICU   \n",
      "4     369         272   164716      210407  carevue            CCU   \n",
      "\n",
      "  LAST_CAREUNIT  FIRST_WARDID  LAST_WARDID              INTIME  \\\n",
      "0          MICU            52           52 2198-02-14 23:27:38   \n",
      "1          MICU            52           52 2170-11-05 11:05:29   \n",
      "2           CCU            57           57 2128-06-24 15:05:20   \n",
      "3          SICU            52           23 2120-08-07 23:12:42   \n",
      "4           CCU            57           57 2186-12-25 21:08:04   \n",
      "\n",
      "              OUTTIME     LOS  \n",
      "0 2198-02-18 05:26:11  3.2490  \n",
      "1 2170-11-08 17:46:57  3.2788  \n",
      "2 2128-06-27 12:32:29  2.8939  \n",
      "3 2120-08-10 00:39:04  2.0600  \n",
      "4 2186-12-27 12:01:13  1.6202  \n",
      "0.0\n",
      "57786\n",
      "58976\n"
     ]
    }
   ],
   "source": [
    "print(icustays.columns)\n",
    "print(icustays.head())\n",
    "print(icustays[\"HADM_ID\"].isna().mean())\n",
    "print(icustays[\"HADM_ID\"].nunique())\n",
    "print(admissions[\"HADM_ID\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844082bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 2210\n"
     ]
    }
   ],
   "source": [
    "print(admissions[\"ADMITTIME\"].dt.year.min(), admissions[\"ADMITTIME\"].dt.year.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bedb3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2196 2153 2157 2139 2160 2126 2191 2177 2172 2108]\n",
      "[2198 2170 2128 2120 2186 2141 2114 2147 2132 2164]\n"
     ]
    }
   ],
   "source": [
    "print(admissions[\"ADMITTIME\"].dt.year.unique()[:10])\n",
    "print(icustays[\"INTIME\"].dt.year.unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2367e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n",
      "0    165315\n",
      "1    152223\n",
      "2    124321\n",
      "3    161859\n",
      "4    129635\n",
      "Name: HADM_ID, dtype: int64\n",
      "0    110404\n",
      "1    106296\n",
      "2    188028\n",
      "3    173727\n",
      "4    164716\n",
      "Name: HADM_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(admissions[\"HADM_ID\"].dtype)\n",
    "print(icustays[\"HADM_ID\"].dtype)\n",
    "print(admissions[\"HADM_ID\"].head())\n",
    "print(icustays[\"HADM_ID\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad56621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping HADM_IDs: 57786\n",
      "Total admissions: 58976\n",
      "Total icu stays: 61532\n"
     ]
    }
   ],
   "source": [
    "overlap = len(set(admissions[\"HADM_ID\"]).intersection(icustays[\"HADM_ID\"]))\n",
    "print(\"Overlapping HADM_IDs:\", overlap)\n",
    "print(\"Total admissions:\", len(admissions))\n",
    "print(\"Total icu stays:\", len(icustays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admissions before cleaning: (58976, 19)\n",
      "Admissions after timestamp drop: (58976, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Admissions before cleaning:\", admissions.shape)\n",
    "adm_pat = admissions.copy()\n",
    "adm_pat[\"ADMITTIME\"] = pd.to_datetime(adm_pat[\"ADMITTIME\"], errors=\"coerce\")\n",
    "adm_pat[\"DISCHTIME\"] = pd.to_datetime(adm_pat[\"DISCHTIME\"], errors=\"coerce\")\n",
    "print(\"Admissions after timestamp drop:\", adm_pat.dropna(subset=[\"ADMITTIME\",\"DISCHTIME\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU stays in test_merge: 61532\n",
      "Unique ICU stays in test_merge: 61532\n"
     ]
    }
   ],
   "source": [
    "test_merge = adm_pat.merge(icustays, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"left\")\n",
    "print(\"ICU stays in test_merge:\", test_merge[\"ICUSTAY_ID\"].notna().sum())\n",
    "print(\"Unique ICU stays in test_merge:\", test_merge[\"ICUSTAY_ID\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa905ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step A ICU stays: 61532\n"
     ]
    }
   ],
   "source": [
    "# Step A\n",
    "sA = adm_pat.merge(icustays, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"left\")\n",
    "print(\"Step A ICU stays:\", sA[\"ICUSTAY_ID\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step B ICU stays: 61532\n"
     ]
    }
   ],
   "source": [
    "adm_pat2 = adm_pat.copy()\n",
    "adm_pat2[\"ADMITTIME\"] = pd.to_datetime(adm_pat2[\"ADMITTIME\"], errors=\"coerce\")\n",
    "adm_pat2[\"DISCHTIME\"] = pd.to_datetime(adm_pat2[\"DISCHTIME\"], errors=\"coerce\")\n",
    "\n",
    "sB = adm_pat2.merge(icustays, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"left\")\n",
    "print(\"Step B ICU stays:\", sB[\"ICUSTAY_ID\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272658d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step C ICU stays: 61532\n"
     ]
    }
   ],
   "source": [
    "adm_pat3 = adm_pat2.dropna(subset=[\"ADMITTIME\",\"DISCHTIME\"])\n",
    "\n",
    "sC = adm_pat3.merge(icustays, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"left\")\n",
    "print(\"Step C ICU stays:\", sC[\"ICUSTAY_ID\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea028c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step D ICU stays: 61532\n"
     ]
    }
   ],
   "source": [
    "adm_pat4 = adm_pat3[\n",
    "    adm_pat3[\"ADMITTIME\"].dt.year.between(2000, 3000)\n",
    "]\n",
    "\n",
    "sD = adm_pat4.merge(icustays, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"left\")\n",
    "print(\"Step D ICU stays:\", sD[\"ICUSTAY_ID\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdcb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU after merging: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"ICU after merging:\", merged[\"ICUSTAY_ID\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f70cdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID_x</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_51222</th>\n",
       "      <th>mean_51265</th>\n",
       "      <th>mean_51300</th>\n",
       "      <th>min_50912</th>\n",
       "      <th>min_50971</th>\n",
       "      <th>min_50983</th>\n",
       "      <th>min_51006</th>\n",
       "      <th>min_51222</th>\n",
       "      <th>min_51265</th>\n",
       "      <th>min_51300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>2138-07-17 19:04:00</td>\n",
       "      <td>2138-07-21 15:48:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>8.250</td>\n",
       "      <td>153.50</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>2101-10-20 19:08:00</td>\n",
       "      <td>2101-10-31 13:58:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>9.025</td>\n",
       "      <td>255.25</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>138.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>190.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>2191-03-16 00:28:00</td>\n",
       "      <td>2191-03-23 18:41:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>HOME WITH HOME IV PROVIDR</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>10.600</td>\n",
       "      <td>201.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>141.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>201.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>178980</td>\n",
       "      <td>2103-02-02 04:31:00</td>\n",
       "      <td>2103-02-04 12:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>14.900</td>\n",
       "      <td>309.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>309.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>2175-05-30 07:15:00</td>\n",
       "      <td>2175-06-15 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>9.500</td>\n",
       "      <td>322.50</td>\n",
       "      <td>6.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>134.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>315.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID_x  SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "0         1           2   163353  2138-07-17 19:04:00  2138-07-21 15:48:00   \n",
       "1         2           3   145834  2101-10-20 19:08:00  2101-10-31 13:58:00   \n",
       "2         3           4   185777  2191-03-16 00:28:00  2191-03-23 18:41:00   \n",
       "3         4           5   178980  2103-02-02 04:31:00  2103-02-04 12:15:00   \n",
       "4         5           6   107064  2175-05-30 07:15:00  2175-06-15 16:00:00   \n",
       "\n",
       "  DEATHTIME ADMISSION_TYPE         ADMISSION_LOCATION  \\\n",
       "0       NaN        NEWBORN  PHYS REFERRAL/NORMAL DELI   \n",
       "1       NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "2       NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "3       NaN        NEWBORN  PHYS REFERRAL/NORMAL DELI   \n",
       "4       NaN       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
       "\n",
       "          DISCHARGE_LOCATION INSURANCE  ... mean_51222 mean_51265 mean_51300  \\\n",
       "0                       HOME   Private  ...      8.250     153.50       6.25   \n",
       "1                        SNF  Medicare  ...      9.025     255.25       6.25   \n",
       "2  HOME WITH HOME IV PROVIDR   Private  ...     10.600     201.00       6.25   \n",
       "3                       HOME   Private  ...     14.900     309.00       6.25   \n",
       "4           HOME HEALTH CARE  Medicare  ...      9.500     322.50       6.25   \n",
       "\n",
       "  min_50912 min_50971 min_50983 min_51006  min_51222  min_51265  min_51300  \n",
       "0       0.9       4.0     138.0      18.0        0.0        5.0       6.25  \n",
       "1       2.4       3.9     138.0      41.0        7.8      190.0       6.25  \n",
       "2       0.5       3.3     141.0      10.0       10.6      201.0       6.25  \n",
       "3       0.9       4.0     138.0      18.0       14.9      309.0       6.25  \n",
       "4      10.0       4.8     134.0      62.0        9.2      315.0       6.25  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bdec17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
